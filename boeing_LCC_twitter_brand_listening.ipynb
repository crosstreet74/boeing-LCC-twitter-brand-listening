{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "boeing-LCC-twitter-brand-listening.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LNZuRQbe3C8c",
        "colab_type": "text"
      },
      "source": [
        "# boeing-LCC-twitter-brand-listening\n",
        "This application helps the LCC brands to listen the clients' feedback about their services via twitter sentiment analysis and keyword clustering"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d5oZhtEyBiIH",
        "colab_type": "text"
      },
      "source": [
        "## Load GitHub"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rVfLilWLAeNK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!git clone https://github.com/crosstreet74/boeing-LCC-twitter-brand-listening\n",
        "%cd boeing-LCC-twitter-brand-listening\n",
        "!ls"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R7TNwzgv3cNI",
        "colab_type": "text"
      },
      "source": [
        "## crawling tweets\n",
        "\n",
        "Crawl tweets at the time around each incident below\n",
        "* United Airlines / T'way Air\n",
        "* Boeing 737 NG (to be considered)\n",
        " * 2016년 3월 19일, 플라이두바이 981편 추락 사고, 탑승자 62명 전원 사망.\n",
        " * 2018년 4월 17일, 사우스웨스트 항공 1380편 엔진파손 사건, 탑승자 149명 중 1명 사망, 148명 생존.\n",
        " * 2019년 9월 경, FAA, Boeing 737 NG crack report\n",
        "* Boeing 737 MAX\n",
        " * 2018년 10월 29일, 라이온 에어 소속 737 MAX 8이 바다로 추락, 189명 전원 사망\n",
        " * 2019년 3월 10일, 에티오피아 항공 소속 737 MAX 8 여객기 추락, 157명 전원 사망\n",
        "\n",
        "GetOldtweets3\n",
        "* TweetCriteria\n",
        " * lang=en, query('united airline 737 MAX'), since='2018-10-01', until='2019-11-30'\n",
        "\n",
        "Less tweets for the korean search, chose english search\n",
        "\n",
        "Removed url links in the tweets with manual edit"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hS0KRN4rDfKX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pip install GetOldTweets3"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qHgZgRDC20jg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import time\n",
        "import datetime\n",
        "import pandas\n",
        "import GetOldTweets3 as got\n",
        "from tqdm import tqdm_notebook\n",
        "from random import uniform"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RozhRyS04RQJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "start = datetime.datetime.strptime(\"2018-10-01\", \"%Y-%m-%d\")\n",
        "end = datetime.datetime.strptime(\"2019-11-30\", \"%Y-%m-%d\")\n",
        "date_generated = [\n",
        "    start + datetime.timedelta(days=x) for x in range(0, (end-start).days)]\n",
        "\n",
        "days_range = []\n",
        "\n",
        "for date in date_generated:\n",
        "    days_range.append(date.strftime(\"%Y-%m-%d\"))\n",
        "\n",
        "print(\"=== 설정된 트윗 수집 기간은 {} 에서 {} 까지 입니다 ===\".format(\n",
        "    days_range[0], days_range[-1]))\n",
        "print(\"=== 총 {}일 간의 데이터 수집 ===\".format(len(days_range)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ct2_-d1GDtEC",
        "colab_type": "text"
      },
      "source": [
        "Takes a few hours to search & copy the tweets to the csv file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cm_M5Gnx4ZiI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tweetCriteria = got.manager.TweetCriteria().setQuerySearch('united airline 737 MAX')\\\n",
        "                                           .setSince(days_range[0])\\\n",
        "                                           .setUntil(days_range[-1])\\\n",
        "                                           .setMaxTweets(-1)\\\n",
        "                                           .setLang('en') \n",
        "\n",
        "print(\"Collecting data start.. from {} to {}\".format(\n",
        "    days_range[0], days_range[-1]))\n",
        "\n",
        "start_time = time.time()\n",
        "tweet = got.manager.TweetManager.getTweets(tweetCriteria)\n",
        "\n",
        "print(\"Collecting data end.. {0:0.2f} Minutes\".format(\n",
        "    (time.time() - start_time)/60))\n",
        "print(\"=== Total # of tweets is {} ===\".format(len(tweet)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JpRtW_yr4d6q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tweet_list = []\n",
        "\n",
        "for index in tqdm_notebook(tweet):\n",
        "    content = index.text\n",
        "    tweet_date = index.date.strftime(\"%Y-%m-%d\")\n",
        "    info_list = [tweet_date, content]\n",
        "    tweet_list.append(info_list)\n",
        "    time.sleep(uniform(1, 3))\n",
        "\n",
        "twitter_df = pandas.DataFrame(tweet_list,\n",
        "                              columns=[\"date\", \"text\"])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aG-FBXxM4gqG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "twitter_df.to_csv(\"crawled_tweets_{}_to_{}.csv\".format(\n",
        "    days_range[0], days_range[-1]), index=False)\n",
        "print(\"=== {} tweets are successfully saved ===\".format(len(tweet_list)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5I_FHZFJ5gDf",
        "colab_type": "text"
      },
      "source": [
        "## Tweets Sentiment Analysis\n",
        "\n",
        "used negative, positive words from below\n",
        "* https://www.cs.uic.edu/~liub/FBS/sentiment-analysis.html\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hyoOX0I969hN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import nltk\n",
        "import matplotlib.pyplot as plt\n",
        "from collections import Counter\n",
        "from datetime import date\n",
        "nltk.download('punkt')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6AKek6cX7BFR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def words2lists(filename):\n",
        "    lists = []\n",
        "    file = open(filename, \"r\", encoding=\"utf-8\")\n",
        "    while True:\n",
        "        line = file.readline().rstrip(\"\\n\")\n",
        "        if line:\n",
        "            lists.append(line)\n",
        "        else:\n",
        "            break\n",
        "    return lists\n",
        "\n",
        "\n",
        "def csv2list(filename):\n",
        "    lists = []\n",
        "    file = open(filename, \"r\", encoding=\"utf-8\")\n",
        "    while True:\n",
        "        line = file.readline().rstrip(\"\\n\")\n",
        "        if line:\n",
        "            line = line.split(\"`\")\n",
        "            lists.append(line)\n",
        "        else:\n",
        "            break\n",
        "    return lists"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L_juqtyp7E2l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def sentimentalize(words):\n",
        "    poslen = len(POSITIVE_WORDS.intersection(words))\n",
        "    neglen = len(NEGATIVE_WORDS.intersection(words))\n",
        "\n",
        "    if poslen > 0 and neglen == 0:\n",
        "        return POSITIVE\n",
        "    elif poslen == 0 and neglen > 0:\n",
        "        return NEGATIVE\n",
        "    elif poslen > 0 and neglen > 0:\n",
        "        return BOTH\n",
        "    else:\n",
        "        return UNKNOWN\n",
        "\n",
        "\n",
        "def count_sentiment(sentences):\n",
        "    sents = Counter()\n",
        "    words = Counter()\n",
        "\n",
        "    for sentence in sentences:\n",
        "        sentiment = sentimentalize(sentence)\n",
        "        sents[sentiment] += 1\n",
        "        words[sentiment] += len(sentence)\n",
        "\n",
        "    return sents, words\n",
        "\n",
        "\n",
        "def parse_sentiment(text):\n",
        "    sentences = [\n",
        "        [word.lower() for word in nltk.word_tokenize(sentence)]\n",
        "        for sentence in nltk.sent_tokenize(text)\n",
        "    ]\n",
        "    sents, words = count_sentiment(sentences)\n",
        "    total = sum(words.values())\n",
        "\n",
        "    for sentiment, count in words.items():\n",
        "        pcent = (count / total) * 100\n",
        "        nsents = sents[sentiment]\n",
        "        # print(\"{:0.3f}% {} ({} sentences)\".format(pcent, sentiment, nsents))\n",
        "    return sentiment\n",
        "\n",
        "\n",
        "def parse_list(data):\n",
        "    result = []\n",
        "    for item in data:\n",
        "        sentiment = parse_sentiment(item[1])\n",
        "        # tweet_date = date.fromisoformat(item[0])\n",
        "        result.append([\n",
        "            # tweet_date.year, tweet_date.month, tweet_date.day,\n",
        "            item[0], sentiment])\n",
        "    return result"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bqFXxZJf7HW8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "POSITIVE_WORDS_DIR = os.path.join('feature_words', 'positive-words.txt')\n",
        "NEGATIVE_WORDS_DIR = os.path.join('feature_words', 'negative-words.txt')\n",
        "CRAWLED_DATA_DIR = os.path.join('crawled_data.csv')\n",
        "POSITIVE = 'positive'\n",
        "NEGATIVE = 'negative'\n",
        "UNKNOWN = 'unknown'\n",
        "BOTH = 'both'\n",
        "POSITIVE_WORDS = set(words2lists(POSITIVE_WORDS_DIR))\n",
        "NEGATIVE_WORDS = set(words2lists(NEGATIVE_WORDS_DIR))\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    results = []\n",
        "    data = csv2list(CRAWLED_DATA_DIR)\n",
        "    results = parse_list(data)\n",
        "    print(results)\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}